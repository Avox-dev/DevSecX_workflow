#!/usr/bin/env python3
import os
import requests
from Grok_api import Grok_req
from bandit_result import run_bandit_cli
import argparse

def get_source_files(root_dir, extensions=(".py", ".js", ".java", ".cpp", ".c", ".h")):
    """
    ì£¼ì–´ì§„ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ë‚´ì—ì„œ ì§€ì •ëœ í™•ì¥ìë¥¼ ê°€ì§„ ëª¨ë“  ì†ŒìŠ¤ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Parameters:
        root_dir (str): ì†ŒìŠ¤ íŒŒì¼ ê²€ìƒ‰ì„ ì‹œì‘í•  ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ.
        extensions (tuple): ê²€ìƒ‰í•  íŒŒì¼ í™•ì¥ìë“¤ì˜ íŠœí”Œ. ê¸°ë³¸ê°’ì€ (".py", ".js", ".java", ".cpp", ".c", ".h") ì…ë‹ˆë‹¤.
    
    Returns:
        list: í•´ë‹¹ í™•ì¥ìë¥¼ ê°€ì§„ íŒŒì¼ë“¤ì˜ ì „ì²´ ê²½ë¡œ ëª©ë¡.
    """
    source_files = []
    for dirpath, _, filenames in os.walk(root_dir):
        for filename in filenames:
            if filename.endswith(extensions):
                source_files.append(os.path.join(dirpath, filename))
    return source_files



def main():
    parser = argparse.ArgumentParser(description="LLM API ìš”ì²­ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--api-key", required=True, help="LLM API í‚¤")
    args = parser.parse_args()

    source_files_list=get_source_files('../DevSecX')
    
    for file_path in source_files_list:
        try:
            # Bandit ìŠ¤ìº” ì‹¤í–‰ (run_bandit_cli í•¨ìˆ˜ê°€ íŒŒì¼ ê²½ë¡œë¥¼ ì¸ìë¡œ ë°›ê³  ê²°ê³¼ ë¬¸ìì—´ ë°˜í™˜)
            scan_result = run_bandit_cli(file_path)
            promft=scan_result+'''
            ìœ„ ê²°ê³¼ë¥¼ ë³´ê³  ë°‘ì— ì¡°ê±´ëŒ€ë¡œ ëª…ì‹¬í•˜ê³  ì‘ë‹µí•˜ì„¸ìš”
            1.í•œêµ­ì–´ë¡œ ë‹µë³€í• ê²ƒ
            2.ì•„ë˜ ì£¼ì–´ì§„ ì–‘ì‹ëŒ€ë¡œ ì‘ì„±í• ê²ƒ
            [Example report form].

            1. Overview.  
            - Scan run date and time and target file information:  
            - Summary of the overall scan results (e.g., total number of issues detected, severity distribution, etc.):

            2. Detailed vulnerability analysis  
            - Vulnerability ID: Example) B307  
            - Vulnerability Description:  
            - Issues and security concerns related to the use of dangerous functions (e.g., eval).  
            - Severity and confidence level: e.g.) Medium, High  
            - Related CWE: CWE-78 (OS Instruction Injection)  
            - Found in: File path and code line number  
            - References: Links to related documentation

            3. Impact Analysis and Risk Assessment  
            - The impact of the vulnerability on the system or application:  
            - Security risk assessment and prioritization:

            4. Recommendations and remediation.  
            - Specific recommendations for improving the vulnerability (e.g., recommendation to use ast.literal_eval instead of eval)  
            - Suggestions for additional security best practices:

            5. Conclusion  
            - Summary of the report and recommendations for future remediation:
            '''
            LLM_res=Grok_req(promft,args.api_key)
            
        except Exception as e:
            print(f"{file_path} ìŠ¤ìº” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ê²°ê³¼ íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
        output_path = "response.txt"

        # LLM_res ê°’ì´ ë¹„ì–´ ìˆëŠ”ì§€ í™•ì¸
        if not LLM_res:
            print("âš ï¸ LLM_res is empty! No data to write.")
        else:
            with open(output_path, "a", encoding="utf-8") as outfile:
                outfile.write(LLM_res + "\n")
            
            print(f"âœ… Response saved to: {output_path}")

        # ìµœì¢…ì ìœ¼ë¡œ response.txtê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if os.path.exists(output_path):
            print(f"ğŸ“‚ response.txt exists at: {os.path.abspath(output_path)}")
        else:
            print("âŒ response.txt was not created.")

                
    print("ìŠ¤ìº”ê²°ê³¼ response.txtì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
